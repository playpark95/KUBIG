{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JWG30YuzV7I"
   },
   "source": [
    "# **CNN + 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAnbMhCw0icL"
   },
   "source": [
    "# 라이브러리 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpRuMNjw0f1R"
   },
   "outputs": [],
   "source": [
    "#import Libraries -1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics, preprocessing, pipeline, model_selection, naive_bayes\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling1D, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWD7FCsaccV8"
   },
   "outputs": [],
   "source": [
    "#importing libraries-2\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwDd-gSm0_Bo"
   },
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "train = pd.read_csv('/content/drive/MyDrive/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/test_x.csv')\n",
    "sample = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "PUbHPsy1B9Wy",
    "outputId": "65167ff5-b6d7-4d09-edf6-18687ea0913e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  author\n",
       "0      0  He was almost choking. There was so much, so m...       3\n",
       "1      1             “Your sister asked for it, I suppose?”       2\n",
       "2      2   She was engaged one day as she walked, in per...       1\n",
       "3      3  The captain was in the porch, keeping himself ...       4\n",
       "4      4  “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqRkrekDDEzk",
    "outputId": "aa7c11f3-5c19-4ba0-9a5b-8d7e733399ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    15063\n",
       "0    13235\n",
       "2    11554\n",
       "4     7805\n",
       "1     7222\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#작가별 문장 개수 파악하기\n",
    "train['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6JFkFX9B-lg",
    "outputId": "95403076-ab25-4d7c-b6f1-fca5b919abb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19617, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSCThoudYeA_"
   },
   "source": [
    "# Feature Engineering 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KS_m4uZGb0mU"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7beBnZOBGAN",
    "outputId": "9315d017-b260-4cd1-9db3-0aac493212ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGBm7dP9AZvI"
   },
   "outputs": [],
   "source": [
    "# replace\n",
    "train['text'] = train['text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "test['text'] =test['text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "\n",
    "## text 내 단어 개수\n",
    "train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "## text 내 고유단어 개수\n",
    "train[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "## text 내 character 개수\n",
    "train[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "## text 내 stopword 개수\n",
    "eng_stopwords = nltk.corpus.stopwords.words('english')\n",
    "train[\"num_stopwords\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test[\"num_stopwords\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cY8I5YiwBO7r"
   },
   "outputs": [],
   "source": [
    "## text 내 punctuation 개수\n",
    "import string\n",
    "train[\"num_punctuations\"] =train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test[\"num_punctuations\"] =test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "## text 내 upper case 단어 개수\n",
    "train[\"num_words_upper\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test[\"num_words_upper\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "## text 내 title case 단어 개수\n",
    "train[\"num_words_title\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test[\"num_words_title\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "## text 내 평균 단어 길이\n",
    "train[\"mean_word_len\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "IjBC6A1CcCyi",
    "outputId": "82f36473-bed4-4021-a868-bcdfac843870"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54874</th>\n",
       "      <td>54874</td>\n",
       "      <td>“Is that you, Mr. Smith?” odin whispered. “I h...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54875</th>\n",
       "      <td>54875</td>\n",
       "      <td>I told my plan to the captain, and between us ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54876</th>\n",
       "      <td>54876</td>\n",
       "      <td>\"Your sincere well-wisher, friend, and sister...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54877</th>\n",
       "      <td>54877</td>\n",
       "      <td>“Then you wanted me to lend you money?”</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54878</th>\n",
       "      <td>54878</td>\n",
       "      <td>It certainly had not occurred to me before, bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54879 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  ... mean_word_len\n",
       "0          0  ...      4.239130\n",
       "1          1  ...      4.571429\n",
       "2          2  ...      4.614035\n",
       "3          3  ...      4.517241\n",
       "4          4  ...      4.871795\n",
       "...      ...  ...           ...\n",
       "54874  54874  ...      4.666667\n",
       "54875  54875  ...      4.277778\n",
       "54876  54876  ...      6.375000\n",
       "54877  54877  ...      4.000000\n",
       "54878  54878  ...      4.062500\n",
       "\n",
       "[54879 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MS7960P9CnwZ"
   },
   "outputs": [],
   "source": [
    "# Clean text\n",
    "def clean_text(text):\n",
    "    return re.sub('[^a-zA-Z]', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDXY5ByCCrPT"
   },
   "outputs": [],
   "source": [
    "train['text_cleaned'] = train['text'].apply(lambda x: clean_text(x))\n",
    "test['text_cleaned'] = test['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SQMnEAodqHO"
   },
   "outputs": [],
   "source": [
    "# stopword 제거\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVIdCSLJDrTe"
   },
   "outputs": [],
   "source": [
    "# text feature 추출\n",
    "def extract_features(df):\n",
    "    df['len'] = df['text'].apply(lambda x: len(x))\n",
    "    df['n_words'] = df['text'].apply(lambda x: len(x.split(' ')))\n",
    "    df['n_.'] = df['text'].str.count('\\.')\n",
    "    df['n_...'] = df['text'].str.count('\\...')\n",
    "    df['n_,'] = df['text'].str.count('\\,')\n",
    "    df['n_:'] = df['text'].str.count('\\:')\n",
    "    df['n_;'] = df['text'].str.count('\\;')\n",
    "    df['n_-'] = df['text'].str.count('\\-')\n",
    "    df['n_?'] = df['text'].str.count('\\?')\n",
    "    df['n_!'] = df['text'].str.count('\\!')\n",
    "    df['n_\\''] = df['text'].str.count('\\'')\n",
    "    df['n_\"'] = df['text'].str.count('\\\"')\n",
    "    df.drop(['text_cleaned'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oX_aj6wLEM4t",
    "outputId": "baad834a-a60d-432f-82fe-81c6856b5a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train...\n",
      "Processing test...\n"
     ]
    }
   ],
   "source": [
    "print('Processing train...')\n",
    "extract_features(train)\n",
    "print('Processing test...')\n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6_U1EV3FPLo",
    "outputId": "e5575810-266f-498c-84a8-672bba8ba149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (54879, 2132503)\n",
      "Tfidf_test: (19617, 1773623)\n"
     ]
    }
   ],
   "source": [
    "## TF-IDF 적용\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,3), min_df =0,max_df=0.9,lowercase=False, use_idf=True)\n",
    "train_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.fit_transform(test['text'].values.tolist())\n",
    "print('Tfidf_train:',train_tfidf.shape)\n",
    "print('Tfidf_test:',test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC8dsmmJB4KD"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UmHNVaKEviV",
    "outputId": "cb18f96d-f733-4fc9-a2b7-aa9586227c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import keras done\n"
     ]
    }
   ],
   "source": [
    "# impoting libraries for CNN modeling\n",
    "from keras.layers import Embedding, GRU, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "import gc\n",
    "print('import keras done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxaYkEVhE5g-"
   },
   "outputs": [],
   "source": [
    "#importing libraries for NB features\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcMpDBKRKCnn"
   },
   "outputs": [],
   "source": [
    "# importing libraries for 1D CNN\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O-K0PVxI0GF",
    "outputId": "9260fdff-8ea6-4135-c9fb-785f395eedf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879,) (19617,) (54879,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "X_train = train['text'].values\n",
    "X_test = test['text'].values\n",
    "y = train['author'].values\n",
    "print(X_train.shape, X_test.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j55UO4QBI3ZF",
    "outputId": "00cad4e9-4b40-47a2-effc-289b5e32bb36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['He was almost choking  There was so much  so much he wanted to say  but strange exclamations were all that came from his lips  The Pole gazed fixedly at him  at the bundle of notes in his hand  looked at odin  and was in evident perplexity ',\n",
       "       ' Your sister asked for it  I suppose  ',\n",
       "       ' She was engaged one day as she walked  in perusing Jane s last letter  and dwelling on some passages which proved that Jane had not written in spirits  when  instead of being again surprised by Mr  odin  she saw on looking up that odin was meeting her  Putting away the letter immediately and forcing a smile  she said '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9BREyUpItO0"
   },
   "outputs": [],
   "source": [
    "#parameter setting\n",
    "vocab_size = 20000\n",
    "embedding_dim = 64\n",
    "max_length = 500\n",
    "padding_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFDfeiPFIvjb"
   },
   "outputs": [],
   "source": [
    "# 문장 tokenization\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLHyy3rwJBhG"
   },
   "outputs": [],
   "source": [
    "# text 내 단어들을 숫자 sequence 형태로 변환\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUdGM2kqJEAL",
    "outputId": "fd5d08b7-c7b2-48e9-a53e-db9e45b2b1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 500) (19617, 500)\n"
     ]
    }
   ],
   "source": [
    "trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
    "print(trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QOyQIncJF7L"
   },
   "outputs": [],
   "source": [
    "# K-Fold 함수 설정\n",
    "n_fold = 10\n",
    "n_class = 5\n",
    "seed = 42\n",
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True,random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hv1ZP2l_JI5j"
   },
   "outputs": [],
   "source": [
    "#CNN 모델 설계\n",
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        Dropout(.5),\n",
    "        Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),\n",
    "        Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),    \n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(.5),\n",
    "        Dense(n_class, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=.005))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzkgiWOMJVYf",
    "outputId": "926ed12c-a355-4584-c1f2-b28dcf5b32d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 129s 1s/step - loss: 1.4676 - val_loss: 1.0413\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 128s 1s/step - loss: 0.9523 - val_loss: 0.8569\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 126s 1s/step - loss: 0.7258 - val_loss: 0.7808\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 129s 1s/step - loss: 0.5920 - val_loss: 0.7792\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 127s 1s/step - loss: 0.4976 - val_loss: 0.8046\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 126s 1s/step - loss: 0.4481 - val_loss: 0.8508\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 126s 1s/step - loss: 0.3990 - val_loss: 0.8529\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "training model for CV #2\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 124s 1s/step - loss: 1.5087 - val_loss: 1.2606\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 123s 1s/step - loss: 1.1479 - val_loss: 0.8574\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 123s 1s/step - loss: 0.7381 - val_loss: 0.7849\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 122s 1s/step - loss: 0.5836 - val_loss: 0.7661\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 121s 1s/step - loss: 0.4990 - val_loss: 0.8197\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 121s 1s/step - loss: 0.4452 - val_loss: 0.7656\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 119s 1s/step - loss: 0.3942 - val_loss: 0.8109\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "training model for CV #3\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 1.4845 - val_loss: 1.0641\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.9444 - val_loss: 0.8020\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.6698 - val_loss: 0.7623\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.5439 - val_loss: 0.7566\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.4698 - val_loss: 0.7590\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.4087 - val_loss: 0.7616\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.3742 - val_loss: 0.7926\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "training model for CV #4\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 113s 1s/step - loss: 1.5008 - val_loss: 1.2295\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 1.1640 - val_loss: 0.8957\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.8054 - val_loss: 0.8079\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.6448 - val_loss: 0.7810\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.5430 - val_loss: 0.7783\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.4853 - val_loss: 0.8037\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.4270 - val_loss: 0.7880\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 0.3851 - val_loss: 0.8185\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "training model for CV #5\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 1.4519 - val_loss: 1.0062\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.9400 - val_loss: 0.8097\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 0.6972 - val_loss: 0.7630\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.5707 - val_loss: 0.7693\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.4933 - val_loss: 0.7962\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.4399 - val_loss: 0.8289\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "training model for CV #6\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 1.4733 - val_loss: 1.0147\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.9370 - val_loss: 0.8056\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 0.6991 - val_loss: 0.7722\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.5744 - val_loss: 0.7670\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.4923 - val_loss: 0.7941\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 118s 1s/step - loss: 0.4369 - val_loss: 0.7917\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 118s 1s/step - loss: 0.3918 - val_loss: 0.8082\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "training model for CV #7\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 1.4545 - val_loss: 1.0351\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.9761 - val_loss: 0.7946\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.7062 - val_loss: 0.7600\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.5605 - val_loss: 0.7371\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.4758 - val_loss: 0.7513\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 0.4283 - val_loss: 0.7627\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 0.3827 - val_loss: 0.8031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "training model for CV #8\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 118s 1s/step - loss: 1.4918 - val_loss: 1.0990\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 117s 1s/step - loss: 1.0339 - val_loss: 0.8275\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.7203 - val_loss: 0.7504\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 0.5837 - val_loss: 0.7759\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.4918 - val_loss: 0.7715\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 0.4377 - val_loss: 0.7982\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "training model for CV #9\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 1.4862 - val_loss: 1.0954\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 114s 1s/step - loss: 1.0010 - val_loss: 0.8176\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 115s 1s/step - loss: 0.7042 - val_loss: 0.7729\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 125s 1s/step - loss: 0.5825 - val_loss: 0.7748\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 125s 1s/step - loss: 0.5002 - val_loss: 0.8267\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 123s 1s/step - loss: 0.4394 - val_loss: 0.8032\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "training model for CV #10\n",
      "Epoch 1/10\n",
      "97/97 [==============================] - 120s 1s/step - loss: 1.4692 - val_loss: 1.0096\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 118s 1s/step - loss: 0.9385 - val_loss: 0.8159\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 120s 1s/step - loss: 0.6771 - val_loss: 0.7674\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 121s 1s/step - loss: 0.5567 - val_loss: 0.7395\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 119s 1s/step - loss: 0.4722 - val_loss: 0.7640\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 119s 1s/step - loss: 0.4193 - val_loss: 0.7565\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 118s 1s/step - loss: 0.3802 - val_loss: 0.7656\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델 적용(fitting model)\n",
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True) #EarlyStopping 설정\n",
    "\n",
    "    clf = get_model()    \n",
    "    clf.fit(trn[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
    "            epochs=10,\n",
    "            batch_size=512,\n",
    "            callbacks=[es]) \n",
    "    p_val[i_val, :] = clf.predict(trn[i_val]) #Evaluating model(validation data에 적용)\n",
    "    p_tst += clf.predict(tst) / n_fold #testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhQ5FvqRNnYF",
    "outputId": "e90a2d22-1286-495b-fb6b-a138f34cd044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss (CV):   0.7610\n"
     ]
    }
   ],
   "source": [
    "# Calculating Log_Loss\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4GpN6pG1tZx",
    "outputId": "f6c0bbcf-5eb6-401c-c922-2d62cb6055f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 64)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 165, 128)          57472     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 53, 128)           114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,469,445\n",
      "Trainable params: 1,469,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(clf.summary())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "데이터분석대회_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
